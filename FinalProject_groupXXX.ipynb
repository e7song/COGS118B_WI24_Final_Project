{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Semantic Patterns In Word Difficulty Using Clustering\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Anh Tran\n",
    "- Eric Song\n",
    "- Kendrick Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "This project seeks to find underlying patterns in English words that can contribute to its difficulty. We define word difficulty as the level of complexity in understanding a particular word. Although word difficulty is largely subjective and experience-dependent, we would like to examine whether certain semantic features in English words also carry independent and/or latent significance to difficulty. In fact, this project will build off from another study, the *Word Difficulty Prediction Using Covolutional Neural Networks study* (Basu, Garain, and Naskar, 2019)<a name=\"avishek\"></a>[<sup>[1]</sup>](#avisheknote), that similarly aligns with our project.\n",
    "\n",
    "Our project employs exploratory data analysis and machine learning algorithms to find critical semantic patterns contributing to word difficulty using the study's corpus dataset that also contains semantic features, such as `Length`, `Log_Freq_HAL`, and `I_Zscore`. In our case, we define `I_Zscore` as a metric of word difficulty (0 being easy to understand and 1 being hard to understand). This project attempts to find underlying patterns using various unsupervised learning clustering algorithms, yet our findings were unfortunately poor based on silhouette score metrics. However, since these silhouette score metrics were similarly and consistently low, we concluded that our project was limited by the relatively small corpus dataset and unaccounted external factors that could also contribute to word difficulty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "English is currently the most spoken language in the world at 1.456 billion speakers <a name=\"wiki\"></a>[<sup>[2]</sup>](#wikinote). A large portion of these English speakers are those learning it as a second language <a name=\"wiki\"></a>[<sup>[2]</sup>](#wikinote). Often times, people who are learning the language find it difficult and encounter many challenges such as the complexity of pronunciation and non-obvious rule sets (for instance, think of “read” and “read”<a name=\"adjective\"></a>[<sup>[6]</sup>](#adjectivenote)). To gain a better understanding of how the language is learned by English second language learners, many delve into how difficult it is to learn a particular word of the English language. For example, the Flesch-Kincaid readability tests was created in order to see how difficult a passage in English is to grasp<a name=\"flesch\"></a>[<sup>[3]</sup>](#fleschnote). The test was created based on the need to judge the U.S. Navy recruitment to see their reading comprehension level. The test uses total words, total sentences, total syllables, and total words to plug into an equation to churn out a score.\n",
    "\n",
    "Another research group that looked to analyze English words was <a name=\"avishek\"></a>[<sup>[1]</sup>](#avisheknote). Building on the English Lexicon Project, Basu et. al. looked to use traditional machine learning models as well as a convolutional neural network based prediction model to predict word difficulty. We will build on the foundations that this project and the English Lexicon Project laid out. In particular, we will be using their `I_Zscore` as a metric of word difficulty. The `I_Zscore` is the “standardized mean lexical decision latency for each word” <a name=\"lexicon\"></a>[<sup>[7]</sup>](#lexiconnote)). The lexical decision latency is the time it takes to read a word and decide whether that word is in the English language or not <a name=\"lexical\"></a>[<sup>[8]</sup>](#lexicalnote). Presumably, this is a way for us to decide how difficult a word is. Harder words may have higher lexical decision latency than easier words, as the English Lexicon Project goes to explore.\n",
    "\n",
    "We will, in part, be using unsupervised machine learning techniques to try and discover underlying patterns between words that are classified as easy (closer to 0 on the `I_Zscore`) and words that are classified as hard (closer to 1 on the `I_Zscore`).\n",
    "\n",
    "By discovering certain patterns among English words, such as similarities in its pronunciation or length, many English speakers and learners could leverage these patterns to learn new words that follow a similar convention. These patterns could alternatively provide English speakers and learners insights and expectations about word difficulty, which can facilitate people’s subjective opinions on how language is used and learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The scope of this project's problem statement is to determine what makes an English word difficult semantically and whether easy/difficult words share some underlying similarity that isn't immediately obvious using clustering. For difficult words, we define it as the `I_Zscore` obtained from the *Word Difficulty Prediction Using Covolutional Neural Networks* study<a name=\"avishek\"></a>[<sup>[1]</sup>](#avisheknote). Our success can be measured in some of the following ways: finding clusters that correspond well with the `I_Zscore` and computing silhouette score to evaluate the clustering. To find underlying patterns, we will examine and compare the semantic features (ex. `Length`, `Log_Freq_HAL`, `I_Mean_Accuracy`, etc.) for each word within a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Our dataset of choice is a corpus dataset from the *Word Difficulty Prediction Using Covolutional Neural Networks study* (Basu, Garain, and Naskar, 2019)<a name=\"avishek\"></a>[<sup>[1]</sup>](#avisheknote). The words were tokenized from the SUBTLEXUS corpus of 131 million words.\n",
    "\n",
    "- The raw dataset is also published on from Kaggle: https://www.kaggle.com/datasets/kkhandekar/word-difficulty. \n",
    "- Number of observations: 9 variables, 40481 observations\n",
    "- Description: An observation consists of the `Word`, `Length`, `Freq_HAL`, `Log_Freq_HAL`, `I_Mean_RT`, `I_Zscore`, `I_SD`, `Obs`, and `I_Mean_Accuracy`.\n",
    "- Critical variables for our problem statement is `I_Zscore`, as it denotes the difficulty of a word. This value fluctuates between 0 and 1 for a word with 0 being SIMPLE and 1 being DIFFICULT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Length</th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Log_Freq_HAL</th>\n",
       "      <th>I_Mean_RT</th>\n",
       "      <th>I_Zscore</th>\n",
       "      <th>I_SD</th>\n",
       "      <th>Obs</th>\n",
       "      <th>I_Mean_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>10610626</td>\n",
       "      <td>16.18</td>\n",
       "      <td>798.92</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>333.85</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aah</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>5.40</td>\n",
       "      <td>816.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>186.03</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>5</td>\n",
       "      <td>10806</td>\n",
       "      <td>9.29</td>\n",
       "      <td>736.06</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>289.01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>5</td>\n",
       "      <td>387</td>\n",
       "      <td>5.96</td>\n",
       "      <td>796.27</td>\n",
       "      <td>0.11</td>\n",
       "      <td>171.61</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacus</td>\n",
       "      <td>6</td>\n",
       "      <td>513</td>\n",
       "      <td>6.24</td>\n",
       "      <td>964.40</td>\n",
       "      <td>0.65</td>\n",
       "      <td>489.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Length  Freq_HAL  Log_Freq_HAL  I_Mean_RT  I_Zscore    I_SD   Obs  \\\n",
       "0       a       1  10610626         16.18     798.92     -0.01  333.85  24.0   \n",
       "1     aah       3       222          5.40     816.43      0.21  186.03  21.0   \n",
       "2   Aaron       5     10806          9.29     736.06     -0.11  289.01  32.0   \n",
       "3   aback       5       387          5.96     796.27      0.11  171.61  15.0   \n",
       "4  abacus       6       513          6.24     964.40      0.65  489.00  15.0   \n",
       "\n",
       "   I_Mean_Accuracy  \n",
       "0             0.73  \n",
       "1             0.62  \n",
       "2             0.97  \n",
       "3             0.45  \n",
       "4             0.47  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./data/WordDifficulty.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a brief description of each feature:\n",
    "\n",
    "- `Length`: Number of characters\n",
    "\n",
    "- `Freq_HAL`: Hyperspace Analogue to Language frequency norms based on the HAL corpus of 131 million words. Higher values may indicate more frequent words in a corpus.\n",
    "\n",
    "- `Log_Freq_HAL`: Applied logarithmic transformation to `Freq_HAL`\n",
    "\n",
    "- `I_Mean_RT`: Individual mean reaction time, associated with lexical decision time\n",
    "\n",
    "- `I_Zscore`: Z-score of individual reaction times, associated with word difficulty\n",
    "\n",
    "- `I_SD`: Standard deviation of individual reaction times\n",
    "\n",
    "- `Obs`: Number of observations/individuals experimented with respective word\n",
    "\n",
    "- `I_Mean_Accuracy`: Individual mean accuracy score, average accuracy score in tasks related to word difficulty\n",
    "\n",
    "This dataset appears somewhat preprocessed prior to publishment where some features have a transformed or standardized version of themselves. From glance, we can perform feature selection by removing the `Freq_HAL`, `I_Mean_RT`, `I_SD`, and `Obs` columns as the dataset already offers the same feature but transformed. The crtical feature `I_Zscore` is a function of `I_Mean_RT` and `I_SD`, so including the the latter is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Freq_HAL and Obs columns\n",
    "df = df.drop(['Freq_HAL', 'I_Mean_RT', 'I_SD', 'Obs'], axis=1)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Apply lower to words\n",
    "df['Word'] = df['Word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Use regex to remove any quotes, astericks, and other punctuations\n",
    "pattern = r\"[\\\"*!?.,']\"\n",
    "\n",
    "for index, word in enumerate(df['Word']):\n",
    "    cleaned_word = re.sub(pattern, '', word)\n",
    "    df.loc[index, 'Word'] = cleaned_word\n",
    "    \n",
    "# Remove duplicates\n",
    "df.drop_duplicates('Word', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset can be strengthened by extracting more features, such as:\n",
    "\n",
    "- Vowel Count, also correlated to syllables\n",
    "- Entropy, or the measure of the unpredictability of the word's character. Computed from $H(x)=\\Sigma{p(x)\\log{p(x)}}$\n",
    "- Parts of speech category. Tagged based on the [Penn Treebank Project](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).\n",
    "- Sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vowels\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "num_vowels = []\n",
    "for word in df['Word']:\n",
    "    vowel_count = sum(word.count(vowel) for vowel in vowels)\n",
    "    num_vowels.append(vowel_count)\n",
    "    \n",
    "df['Vowels'] = num_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Word entropy\n",
    "def calculate_entropy(word):\n",
    "    # Frequency of each character\n",
    "    char_counts = Counter(word)\n",
    "\n",
    "    # Calculate the probability of each character\n",
    "    total_chars = len(word)\n",
    "    char_probabilities = {char: count / total_chars for char, count in char_counts.items()}\n",
    "\n",
    "    # Calculate the entropy\n",
    "    entropy = -sum(prob * math.log2(prob) for prob in char_probabilities.values())\n",
    "\n",
    "    return entropy\n",
    "\n",
    "entropy_values = [calculate_entropy(word) for word in df['Word']]\n",
    "df['Entropy'] = entropy_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Kendrick\n",
      "[nltk_data]     Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Kendrick Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download(['vader_lexicon', 'averaged_perceptron_tagger'])\n",
    "\n",
    "# Getting parts of speech\n",
    "word_tags = nltk.pos_tag(df['Word'])\n",
    "word_tags = [word_tag[1] for word_tag in word_tags]\n",
    "\n",
    "df['PoS'] = word_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sentiment score, we look at the compound score for a final vote\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment_scores = [sia.polarity_scores(word)['compound'] for word in df['Word']]\n",
    "\n",
    "df['SentimentScore'] = sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Length</th>\n",
       "      <th>Log_Freq_HAL</th>\n",
       "      <th>I_Zscore</th>\n",
       "      <th>I_Mean_Accuracy</th>\n",
       "      <th>Vowels</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>PoS</th>\n",
       "      <th>SentimentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>16.18</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aah</td>\n",
       "      <td>3</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2</td>\n",
       "      <td>0.918296</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaron</td>\n",
       "      <td>5</td>\n",
       "      <td>9.29</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3</td>\n",
       "      <td>1.921928</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>5</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>1.921928</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacus</td>\n",
       "      <td>6</td>\n",
       "      <td>6.24</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3</td>\n",
       "      <td>2.251629</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Length  Log_Freq_HAL  I_Zscore  I_Mean_Accuracy  Vowels   Entropy  \\\n",
       "0       a       1         16.18     -0.01             0.73       1 -0.000000   \n",
       "1     aah       3          5.40      0.21             0.62       2  0.918296   \n",
       "2   aaron       5          9.29     -0.11             0.97       3  1.921928   \n",
       "3   aback       5          5.96      0.11             0.45       2  1.921928   \n",
       "4  abacus       6          6.24      0.65             0.47       3  2.251629   \n",
       "\n",
       "  PoS  SentimentScore  \n",
       "0  DT             0.0  \n",
       "1  JJ             0.0  \n",
       "2  NN             0.0  \n",
       "3  NN             0.0  \n",
       "4  NN             0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save preprocessed dataset\n",
    "df.to_csv('./data/NewWordDifficulty.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
